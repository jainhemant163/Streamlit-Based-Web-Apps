{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copyright 2020 Assent Compliance Inc.\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#    http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Serverless ML Inferencing with AWS Lambda and TensorFlow Lite\n",
    "\n",
    "> ... A lot of the tutorials you'll find on \"how to get started with TensorFlow machine learning\" talk about training models. Many even just stop there once you've trained the model and then never ever touch it again. ...\n",
    "\n",
    "-- [Alasdair Allan](https://twitter.com/aallan) @ [QCon 2020](https://www.infoq.com/presentations/iot-edge-ml-privacy-security/)\n",
    "\n",
    "In this tutorial we'll be walking through how to train a machine learning model using the [AutoKeras](https://autokeras.com) library, converting the model to [TensorFlow Lite](https://www.tensorflow.org/lite) format, and deploying it to an [AWS Lambda](https://aws.amazon.com/lambda/) environment for highly cost effective and scalable ML inferencing.\n",
    "\n",
    "While [AWS SageMaker](https://aws.amazon.com/sagemaker/) provides a convenient mechanism to deploy TensorFlow models as a REST API using [TensorFlow Serving Endpoints](https://sagemaker.readthedocs.io/en/stable/frameworks/tensorflow/deploying_tensorflow_serving.html), this method does not suit the needs of Assent's Intelligent Document Analysis pipeline, as we are dealing with unpredictable spiky traffic loads. For more information on this project, checkout the recording of the [Intelligent Document Analysis webinar](https://youtu.be/u1ZK2jZx5D0) my colleague Corey Peters co-presented with the AWS team in September 2020.\n",
    "\n",
    "We decided to investigate if it was possible to perform our image and text classification inferencing in an AWS Lambda environment to both reduce our monthly AWS bill and improve system scalability. AWS Lambda currently has a code size limit of 250 MB per Lambda (for non-Docker containers), and this is significantly smaller than the installed size of the [TensorFlow](https://www.tensorflow.org) Python package with dependencies (900+ MB). It is possible to use [Amazon EFS](https://aws.amazon.com/efs/) for AWS Lambda with the regular TensorFlow Python package, as described in [AWS's Building deep learning inference with AWS Lambda and Amazon EFS blog post](https://aws.amazon.com/blogs/compute/building-deep-learning-inference-with-aws-lambda-and-amazon-efs/) however, this approach can have a relatively large [\"cold start\"](https://mikhail.io/serverless/coldstarts/define/) time for your AWS Lambda.\n",
    "\n",
    "The [TensorFlow Lite](https://www.tensorflow.org/lite) project's tag line is:\n",
    "\n",
    "> \"Deploy machine learning models on mobile and IoT devices\". \n",
    "\n",
    "-- https://www.tensorflow.org/lite\n",
    "\n",
    "It provides a much smaller runtime focused on ML inferencing on mobile and IoT devices which have more constrained computing environments (CPU, RAM, storage) than cloud computing environments. Luckily TensorFlow Lite provides a [Python based runtime API](https://www.tensorflow.org/lite/guide/python) for Linux based embedded computers. After some experimentation, we found it is possible to re-use TensorFlow Lite Python run-time in a AWS Lambda environment. There were a few key steps:\n",
    "\n",
    "1. Creating a custom AWS Lambda layer for the TensorFlow Lite Python runtime. This involved compiling the TensorFlow source code to create the TF Lite Python runtime in the AWS Lambda Python [Docker](https://www.docker.com) build container. With dependencies, the installed package size for this is 53 MB, which is approximately 17x smaller than regular TensorFlow!\n",
    "\n",
    "2. Converting our [Keras](https://keras.io) or TensorFlow based models to TensorFlow Lite format.\n",
    "\n",
    "\n",
    "I'll be walking through an example of this below. To keep the ML model training side simple we'll be using the [MNIST database of handwritten digits](http://yann.lecun.com/exdb/mnist/) dataset along with the [AutoKeras Image Classification tutorial](https://autokeras.com/tutorial/image_classification/) to create the model we want to deploy to an AWS Lambda environment. The goal will be to create a REST API that accepts an input image and returns a prediction on what digit is contained in this image along with a confidence score for this prediction.\n",
    "\n",
    "\n",
    "You'll need a computer with the following setup:\n",
    " - Python 3.8\n",
    " - Docker Desktop\n",
    " - an [AWS account](https://aws.amazon.com) (if you wish to deploy the REST API)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training our ML model\n",
    "\n",
    "This section is based on the awesome AutoKeras [Image Classification Tutorial](https://autokeras.com/tutorial/image_classification/).\n",
    "\n",
    "We'll start off by installing AutoKeras using `pip`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install autokeras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's train and evaluate our model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copyright 2020 The AutoKeras Authors.\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\"); \n",
    "# you may not use this file except in compliance with the License. \n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "# http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software \n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS, \n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. \n",
    "# See the License for the specific language governing permissions and \n",
    "# limitations under the License.\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.python.keras.utils.data_utils import Sequence\n",
    "import autokeras as ak\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "print(x_train.shape)  # (60000, 28, 28)\n",
    "print(y_train.shape)  # (60000,)\n",
    "print(y_train[:3])  # array([7, 2, 1], dtype=uint8)\n",
    "\n",
    "# Initialize the image classifier.\n",
    "clf = ak.ImageClassifier(\n",
    "    overwrite=True,\n",
    "    max_trials=1)\n",
    "# Feed the image classifier with training data.\n",
    "clf.fit(x_train, y_train, epochs=1)\n",
    "\n",
    "# Predict with the best model.\n",
    "predicted_y = clf.predict(x_test)\n",
    "print(predicted_y)\n",
    "\n",
    "# Evaluate the best model with testing data.\n",
    "print(clf.evaluate(x_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that the model has been trained, let's [export](https://autokeras.com/tutorial/export/) and save it as a Keras model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export model\n",
    "model = clf.export_model()\n",
    "\n",
    "# save Keras model to disk\n",
    "model.save('keras_image_classifier')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Converting the model to TF Lite format\n",
    "\n",
    "Now that we have a Keras model, we can follow the [TensorFlow Lite converter - Convert a Keras model]( https://www.tensorflow.org/lite/convert#convert_a_keras_model_) guide to convert it to `.tflite` format.\n",
    "\n",
    "We'll save the `.tflite` file to the `src` folder where our AWS Lambda source code is stored."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to TFLite\n",
    "# https://www.tensorflow.org/lite/convert#convert_a_keras_model_\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "# Save the model.\n",
    "with open('src/model.tflite', 'wb') as output:\n",
    "    output.write(tflite_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing out the TF Lite model\n",
    "\n",
    "Let's create a Python `class` to wrap the TensorFlow runtime so the API is more like the AutoKeras API.\n",
    "\n",
    "We'll create a new file in `src/image_classifier.py`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile src/image_classifier.py\n",
    "# Copyright 2020 Assent Compliance Inc.\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#    http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "\n",
    "# https://www.tensorflow.org/lite/guide/python\n",
    "try:\n",
    "    # try TF Lite Runtime first\n",
    "    from tflite_runtime.interpreter import Interpreter\n",
    "except ModuleNotFoundError:\n",
    "    import tensorflow as tf\n",
    "    Interpreter = tf.lite.Interpreter\n",
    "    \n",
    "import numpy as np\n",
    "\n",
    "class ImageClassifier:\n",
    "    def __init__(self, model_filename='model.tflite'):\n",
    "        # load the .tflite model with the TF Lite runtime interpreter\n",
    "        self.interpreter = Interpreter(model_filename)\n",
    "        self.interpreter.allocate_tensors()\n",
    "\n",
    "        # get a handle to the input tensor details\n",
    "        input_details = self.interpreter.get_input_details()[0]\n",
    "        \n",
    "        # get the input tensor index\n",
    "        self.input_index = input_details['index']\n",
    "\n",
    "        # get the shape of the input tensor, so we can rescale the\n",
    "        # input image to the appropriate size when making predictions\n",
    "        input_shape = input_details['shape']\n",
    "        self._input_height = input_shape[1]\n",
    "        self._input_width = input_shape[2]\n",
    "\n",
    "        # get a handle to the input tensor details\n",
    "        output_details = self.interpreter.get_output_details()[0]\n",
    "        \n",
    "        # get the output tensor index\n",
    "        self.output_index = output_details['index']\n",
    "\n",
    "    def predict(self, image):   \n",
    "        # convert the image to grayscale and resize\n",
    "        grayscale_image = image.convert('L').resize((self._input_width, self._input_height))\n",
    "\n",
    "        # convert the image to a numpy array\n",
    "        input = np.asarray(grayscale_image.getdata(), dtype=np.uint8).reshape((1, self._input_width, self._input_height))\n",
    "\n",
    "        # assign the numpy array value to the input tensor\n",
    "        self.interpreter.set_tensor(self.input_index, input)\n",
    "\n",
    "        # invoke the operation\n",
    "        self.interpreter.invoke()\n",
    "\n",
    "        # get output tensor value\n",
    "        output = self.interpreter.get_tensor(self.output_index)\n",
    "\n",
    "        # return the prediction, there was only one input\n",
    "        return output[0]\n",
    "\n",
    "    def classify(self, image):\n",
    "        # get the prediction, output with be array of 10\n",
    "        prediction = self.predict(image)\n",
    "        \n",
    "        # find the index with the largest value\n",
    "        classification = int(np.argmax(prediction))\n",
    "        \n",
    "        # get the score for the largest index\n",
    "        score = float(prediction[classification])\n",
    "\n",
    "        return classification, score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's try out the class with a test image. First we'll need to install the Python [Pillow](https://python-pillow.org) package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install Pillow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the Pillow module to read test images from disk\n",
    "from PIL import Image\n",
    "\n",
    "# import image classifier class from previous step\n",
    "from src.image_classifier import ImageClassifier\n",
    "\n",
    "# load test image from disk\n",
    "zero_image = Image.open('test_images/0.png')\n",
    "\n",
    "# create image classifier instance with path to TF Lite model file\n",
    "image_classifier = ImageClassifier('src/model.tflite')\n",
    "\n",
    "# classify the image\n",
    "classification, score = image_classifier.classify(zero_image)\n",
    "\n",
    "print(f'Image classified as {classification} with score {score}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the TF Lite runtime .whl package\n",
    "\n",
    "The TensorFlow Lite team provides [pre-built](https://www.tensorflow.org/lite/guide/python) Python `.whl` packages for various architectures including Linux (x86-64), but unfortunately the AWS Lambda 3.8 Python environment is not compatible with the pre-built Python Linux (x86-64) package.\n",
    "\n",
    "If you try to run:\n",
    "```\n",
    "pip install https://github.com/google-coral/pycoral/releases/download/release-frogfish/tflite_runtime-2.4.0-cp38-cp38-linux_x86_64.whl\n",
    "```\n",
    "\n",
    "The following error will result:\n",
    "```\n",
    "...\n",
    "aws_lambda_builders.workflows.python_pip.packager.PackageDownloadError: ERROR: tflite_runtime-2.4.0-cp38-cp38-linux_x86_64.whl is not a supported wheel on this platform\n",
    "...\n",
    "```\n",
    "\n",
    "However, we can use some information from the [Build TensorFlow Lite for Raspberry Pi](https://www.tensorflow.org/lite/guide/build_rpi) to build our own `.whl` file for the AWS Lambda's Python 3.8 environment.\n",
    "\n",
    "We'll use the following `Dockerfile` for this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile Dockerfile\n",
    "# Copyright 2020 Assent Compliance Inc.\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#    http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "\n",
    "# Use https://hub.docker.com/r/lambci/lambda as the base container\n",
    "FROM lambci/lambda:build-python3.8 AS stage1\n",
    "\n",
    "# set the working directory to /build\n",
    "WORKDIR /build\n",
    "\n",
    "# download Bazel (used to compile TensorFlow)\n",
    "RUN curl -L https://github.com/bazelbuild/bazel/releases/download/3.7.1/bazel-3.7.1-linux-x86_64 -o /usr/bin/bazel && chmod +x /usr/bin/bazel\n",
    "\n",
    "# make python3 the default python\n",
    "RUN ln -sf /usr/bin/python3 /usr/bin/python\n",
    "    \n",
    "# Use git to clone the TensorFlow source, checkout v2.4.0 branch\n",
    "RUN git clone https://github.com/tensorflow/tensorflow.git --branch v2.4.0 --depth 1\n",
    "\n",
    "# install TensorFlow Lite Python dependencies\n",
    "RUN pip3 install pybind11 numpy\n",
    "\n",
    "# start the TensorFlow Lite build with Bazel\n",
    "RUN BAZEL_FLAGS='--define tflite_with_xnnpack=true' ./tensorflow/tensorflow/lite/tools/pip_package/build_pip_package_with_bazel.sh\n",
    "\n",
    "# copy the built TensorFlow Lite Python .whl file to the Docker host\n",
    "FROM scratch AS export-stage\n",
    "COPY --from=stage1 /build/tensorflow/tensorflow/lite/tools/pip_package/gen/tflite_pip/python3/dist/tflite_runtime-2.4.0-py3-none-any.whl .\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll kick off the `docker build`. The build `.whl` file will be stored in `layers/tflite_runtime/`, for use in the next step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!DOCKER_BUILDKIT=1 docker build --output layers/tflite_runtime/ ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the AWS Serverless Application Model (SAM) infrastructure\n",
    "\n",
    "> The AWS Serverless Application Model (SAM) is an open-source framework for building serverless applications.\n",
    "\n",
    "-- https://aws.amazon.com/serverless/sam/\n",
    "\n",
    "We'll use AWS's `sam` CLI tool for the structure of our Serverless Application, and install it via `pip`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install aws-sam-cli"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our SAM app will have the following folder structure:\n",
    "\n",
    "- `events/` - contains test events as JSON files\n",
    "- `layers/` - contains pre-built Python packages the AWS Lambda depends on\n",
    "- `src/` - contains source code for our AWS Lambda\n",
    "- `template.yaml` - defines the structure of our SAM application\n",
    "\n",
    "### `template.yaml`\n",
    "\n",
    "Now let's look at the `template.yaml`, it defines:\n",
    "- a `Global` section that defines:\n",
    "  - The default AWS Lambda Function timeout in seconds\n",
    "  - The default list of media types the Serverless API should treat as binary content types\n",
    "  \n",
    "- a `Resources` section that defines:\n",
    "  - The AWS Lambda Function that will handle the ML Inferencing\n",
    "  - A Serverless API gateway\n",
    "  - AWS Lambda layer that contains the Python TensorFlow Lite runtime\n",
    "  - AWS Lambda layer that contains the Python [Pillow](https://python-pillow.org) package used for processing Images\n",
    "  \n",
    "- an `Outputs` section that defines fields to be exported one this SAM app is deployed to AWS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile template.yaml\n",
    "# Copyright 2020 Assent Compliance Inc.\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#    http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "\n",
    "AWSTemplateFormatVersion: '2010-09-09'\n",
    "Transform: AWS::Serverless-2016-10-31\n",
    "Description: Sample SAM TF Lite Function\n",
    "\n",
    "# More info about Globals: https://github.com/awslabs/serverless-application-model/blob/master/docs/globals.rst\n",
    "Globals:\n",
    "  Function:\n",
    "    Timeout: 30\n",
    "  Api:\n",
    "    BinaryMediaTypes:\n",
    "    - image~1png\n",
    "    - image~1jpeg\n",
    "\n",
    "Resources:\n",
    "  TFLiteFunction:\n",
    "    Type: AWS::Serverless::Function # More info about Function Resource: https://github.com/awslabs/serverless-application-model/blob/master/versions/2016-10-31.md#awsserverlessfunction\n",
    "    Properties:\n",
    "      CodeUri: src/\n",
    "      Layers:\n",
    "        - !Ref TFLiteRuntimeLayer\n",
    "        - !Ref PillowLayer\n",
    "      Handler: app.lambda_handler\n",
    "      Runtime: python3.8\n",
    "      Events:\n",
    "        Base:\n",
    "          Type: Api\n",
    "          Properties:\n",
    "            Method: any\n",
    "            Path: /\n",
    "            RestApiId: !Ref ServerlessRestApi\n",
    "        Others:\n",
    "          Type: Api\n",
    "          Properties:\n",
    "            Method: any\n",
    "            Path: /{proxy+}\n",
    "            RestApiId: !Ref ServerlessRestApi\n",
    "            \n",
    "  # https://aws.amazon.com/blogs/developer/handling-arbitrary-http-requests-in-amazon-api-gateway/\n",
    "  ServerlessRestApi:\n",
    "    Type: \"AWS::Serverless::Api\"\n",
    "    Properties:\n",
    "      StageName: Prod\n",
    "      DefinitionBody:\n",
    "        openapi: \"3.0\"\n",
    "        info:\n",
    "          title: !Ref \"AWS::StackName\"\n",
    "          version: \"1.0\"\n",
    "        paths:\n",
    "          /:\n",
    "            x-amazon-apigateway-any-method:\n",
    "              responses:\n",
    "                {}\n",
    "            x-amazon-apigateway-integration:\n",
    "              httpMethod: POST\n",
    "              type: aws_proxy\n",
    "              uri: !Sub \"arn:aws:apigateway:${AWS::Region}:lambda:path/2015-03-31/functions/${TFLiteFunction.Arn}/invocations\"\n",
    "          /{proxy+}:\n",
    "            x-amazon-apigateway-any-method:\n",
    "              responses:\n",
    "                {}\n",
    "            x-amazon-apigateway-integration:\n",
    "              httpMethod: POST\n",
    "              type: aws_proxy\n",
    "              uri: !Sub \"arn:aws:apigateway:${AWS::Region}:lambda:path/2015-03-31/functions/${TFLiteFunction.Arn}/invocations\"\n",
    "\n",
    "\n",
    "  # https://aws.amazon.com/blogs/compute/working-with-aws-lambda-and-lambda-layers-in-aws-sam/\n",
    "  TFLiteRuntimeLayer:\n",
    "    Type: AWS::Serverless::LayerVersion\n",
    "    Properties:\n",
    "      LayerName: TFLiteRuntime\n",
    "      Description: TF Lite Runtime Layer\n",
    "      ContentUri: layers/tflite_runtime/\n",
    "      CompatibleRuntimes:\n",
    "        - python3.8\n",
    "      RetentionPolicy: Retain\n",
    "    Metadata:\n",
    "      BuildMethod: python3.8\n",
    "            \n",
    "  PillowLayer:\n",
    "    Type: AWS::Serverless::LayerVersion\n",
    "    Properties:\n",
    "      LayerName: Pillow\n",
    "      Description: Pillow Layer\n",
    "      ContentUri: layers/pillow/\n",
    "      CompatibleRuntimes:\n",
    "        - python3.8\n",
    "      RetentionPolicy: Retain\n",
    "    Metadata:\n",
    "      BuildMethod: python3.8\n",
    "\n",
    "Outputs:\n",
    "  # ServerlessRestApi is an implicit API created out of Events key under Serverless::Function\n",
    "  # Find out more about other implicit resources you can reference within SAM\n",
    "  # https://github.com/awslabs/serverless-application-model/blob/master/docs/internals/generated_resources.rst#api\n",
    "  TFLiteApi:\n",
    "    Description: \"API Gateway endpoint URL for Prod stage for TF Lite function\"\n",
    "    Value: !Sub \"https://${ServerlessRestApi}.execute-api.${AWS::Region}.amazonaws.com/Prod/\"\n",
    "  TFLiteFunction:\n",
    "    Description: \"TF Lite Lambda Function ARN\"\n",
    "    Value: !GetAtt TFLiteFunction.Arn\n",
    "  TFLiteFunctionIamRole:\n",
    "    Description: \"Implicit IAM Role created for TF Lite function\"\n",
    "    Value: !GetAtt TFLiteFunctionRole.Arn\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `src/` folder\n",
    "\n",
    "Now let's go over the files in the `src/` folder.\n",
    "\n",
    "The `app.py` file contains the Python code for our Lambda.\n",
    "\n",
    "It will receive an event for the HTTP POST request, which contains an image, and processes it:\n",
    "\n",
    "1. Verifies the body is base64 encoded (via the API Gateway proxy)\n",
    "2. Decodes the base64 data to bytes\n",
    "3. Uses the image bytes with `Pillow` to create an Image object\n",
    "4. Uses the `image_classifier` instance to classify the image\n",
    "5. Returns a response with a JSON body for the API Gateway to return to the REST API client "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile src/app.py\n",
    "# Copyright 2020 Assent Compliance Inc.\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#    http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "\n",
    "import base64\n",
    "import json\n",
    "\n",
    "from io import BytesIO\n",
    "from PIL import Image\n",
    "\n",
    "from image_classifier import ImageClassifier\n",
    "\n",
    "# create an Image Classifier instance\n",
    "image_classifier = ImageClassifier()\n",
    "        \n",
    "def lambda_handler(event, context):\n",
    "    if event['isBase64Encoded'] is not True:\n",
    "        return {\n",
    "            'statusCode': 400 # Bad Request!\n",
    "        }\n",
    "    \n",
    "    # The event body will have a base64 string containing the image bytes,\n",
    "    # Deocde the base64 string into bytes\n",
    "    image_bytes = base64.b64decode(event['body'])\n",
    "\n",
    "    # Create a Pillow Image from the image bytes\n",
    "    image = Image.open(BytesIO(image_bytes))\n",
    "    \n",
    "    # Use the image classifier to get a prediction for the image\n",
    "    value, score = image_classifier.classify(image)\n",
    "    \n",
    "    # return the response as JSON\n",
    "    return {\n",
    "        \"statusCode\": 200,\n",
    "        \"headers\": {\n",
    "            \"Content-Type\": \"application/json\",\n",
    "        },\n",
    "        \"body\": json.dumps({\n",
    "            'value': value,\n",
    "            'score': score \n",
    "        })\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `sam` CLI requires a `requirements.txt` file in the Python Lambda's in source code folder. We can create an empty file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!touch src/requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In earlier steps we've already placed the necessary `image_classifier.py` and `model.tflite` files in the `src/` folder.\n",
    "\n",
    "### `layers/` folder\n",
    "\n",
    "This folder will contain files to generate the AWS Lambda Layers that will contain the third party Python modules our AWS Lambda depends on.\n",
    "\n",
    "For the `layers/pillow` folder with just need a `requirements.txt` file a single line:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile layers/pillow/requirements.txt\n",
    "Pillow==8.0.1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly for the `layers/tflite_runtime` folder we need a `requirements.txt` file a single line:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile layers/tflite_runtime/requirements.txt\n",
    "tflite_runtime-2.4.0-py3-none-any.whl\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unlike the `layers/pillow/requirements.txt` file which specified the Python module name and version, this file will refer to the `.whl` file we built in an earlier step."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the SAM application\n",
    "\n",
    "We can now use the AWS SAM CLI to build the application, and we'll use the `--use-container` option so that it builds the AWS Lambda Layers defined in the `template.yaml` inside a `Docker` container:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!sam build --use-container"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that our AWS SAM app has been built locally, we can test it out with a test event.\n",
    "\n",
    "The `events/0.json` file contains a Base64 encoded image of a `0`.\n",
    "\n",
    "The expected outcome of this will be a prediction for \"0\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!sam local invoke TFLiteFunction --event events/0.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can try out the other test JSON event files in the `events` folder to ensure the ML model is performing as expected. The `test_images` folder contains the original test images in PNG format."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deploying to AWS\n",
    "\n",
    "We can now deploy the system to AWS, and the `sam` CLI tool can be used for this.\n",
    "\n",
    "Make sure to replace the `<stack name>` and `<region>` in the command below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!sam deploy --stack-name my-tflite-app2 --resolve-s3 --capabilities CAPABILITY_IAM --region us-east-1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that the app is deployed to AWS we can test it out with the `curl` command.\n",
    "\n",
    "Make sure to replace the URL in the command below with the one outputted from the previous step.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!curl -X POST -H 'Content-Type: image/png' --data-binary @'test_images/0.png' https://36mqe9wz5i.execute-api.us-east-1.amazonaws.com/Prod/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "In this tutorial we covered:\n",
    "\n",
    "1. Training an image classification model using the AutoKeras model to classify handwritten digits.\n",
    "2. Converting the model to TensorFlow Lite format.\n",
    "3. Building the TensorFlow Lite Python runtime for usage in AWS Lambda.\n",
    "4. Creating an AWS SAM app that uses the TensorFlow Lite model with the TensorFlow Lite Python runtime to classify an image received over an HTTP API.\n",
    "\n",
    "While a simple model was trained and deployed, you can follow the same process for other models that are trained in TensorFlow and compatible with the TensorFlow Lite runtime."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
