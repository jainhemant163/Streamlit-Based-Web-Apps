## Ml Flow + Delta Lake

Delta Lake is an open format storage layer that delivers reliability, security and performance on your data lake — for both streaming and batch operations. By replacing data silos with a single home for structured, semi-structured and unstructured data, Delta Lake is the foundation of a cost-effective, highly scalable lakehouse.

- With Apache Spark under the hood, Delta Lake delivers massive scale and speed. And because it’s optimized with performance features like indexing. - All data in Delta Lake is stored in open Apache Parquet format, allowing data to be read by any compatible reader. 
- APIs are open and compatible with Apache Spark
- Delta Lake reduces risk by enabling fine-grained access controls for data governance, functionality typically not possible with data lakes. 

### Getting Started 

This tutorial requires the use of a Databricks account to run. Sign up for a new account [here](https://databricks.com/try-databricks).
Create a new cluster and upload the notebook in this directory into the environment. 

Detailed explanation and steps are documented in the notebook. 

### References

[Spark+AI Summit](https://databricks.com/session_na20/machine-learning-data-lineage-with-mlflow-and-delta-lake)


